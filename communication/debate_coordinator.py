"""
è¾©è®ºåè°ƒå™¨
ç®¡ç†ç ”ç©¶å›¢é˜Ÿä¹‹é—´çš„è¾©è®ºæµç¨‹ï¼Œç¡®ä¿å……åˆ†è®¨è®ºå’Œå†³ç­–è¾¾æˆ
"""
from typing import Dict, Any, List, Optional
import random
import json
from datetime import datetime

from core.agent_base import BaseAgent
from core.llm_client import LLMClient
from core.state_manager import (
    AgentRole, 
    DebateState, 
    get_state_manager,
    MessageType
)
from agents.researchers import BullResearcher, BearResearcher
from utils.logger import get_logger
from tools.result_emitters import emit_debate_quality_evaluation, emit_debate_judgment

logger = get_logger()


class DebateCoordinator(BaseAgent):
    """è¾©è®ºåè°ƒå™¨"""
    
    def __init__(
        self, 
        bull_researcher: BullResearcher,
        bear_researcher: BearResearcher,
        judge_llm: LLMClient,
        max_rounds: int = 3,
        consensus_threshold: float = 0.6,
        debate_llm_pool: Optional[List[LLMClient]] = None,
        randomize_models: bool = False
    ):
        """åˆå§‹åŒ–è¾©è®ºåè°ƒå™¨
        
        Args:
            bull_researcher: å¤šå¤´ç ”ç©¶å‘˜
            bear_researcher: ç©ºå¤´ç ”ç©¶å‘˜
            judge_llm: åˆ¤æ–­LLMå®¢æˆ·ç«¯
            max_rounds: æœ€å¤§è¾©è®ºè½®æ•°
            consensus_threshold: å…±è¯†é˜ˆå€¼
        """
        # åˆå§‹åŒ–BaseAgent
        tools = [emit_debate_quality_evaluation, emit_debate_judgment]
        super().__init__(
            role=AgentRole.DEBATE_COORDINATOR,
            name="è¾©è®ºåè°ƒå™¨",
            llm_client=judge_llm,
            tools=tools
        )
        
        self.bull_researcher = bull_researcher
        self.bear_researcher = bear_researcher
        self.judge_llm = judge_llm
        self.max_rounds = max_rounds
        self.consensus_threshold = consensus_threshold
        self.state_manager = get_state_manager()
        self.debate_llm_pool = debate_llm_pool or [judge_llm]
        self.randomize_models = randomize_models and len(self.debate_llm_pool) > 1
    
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è¾©è®ºè¯·æ±‚ï¼ˆBaseAgentæŠ½è±¡æ–¹æ³•å®ç°ï¼‰
        
        Args:
            context: åŒ…å«symbolã€analysis_reportsã€market_contextçš„ä¸Šä¸‹æ–‡
            
        Returns:
            è¾©è®ºç»“æœ
        """
        # å§”æ‰˜ç»™conduct_research_debateæ–¹æ³•
        symbol = context.get('symbol', '')
        analysis_reports = context.get('analysis_reports', {})
        market_context = context.get('market_context', {})
        
        return self.conduct_research_debate(symbol, analysis_reports, market_context)
    
    def _serialize_analysis_reports(self, analysis_reports: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
        """å°†AnalysisReportå¯¹è±¡åºåˆ—åŒ–ä¸ºå¯JSONåŒ–çš„å­—å…¸
        
        Args:
            analysis_reports: åŒ…å«AnalysisReportå¯¹è±¡çš„å­—å…¸
            
        Returns:
            åºåˆ—åŒ–åçš„å­—å…¸
        """
        serializable_reports = {}
        for analyst_type, report in analysis_reports.items():
            if hasattr(report, 'to_dict'):
                serializable_reports[analyst_type] = report.to_dict()
            else:
                serializable_reports[analyst_type] = report
        return serializable_reports
    
    def _serialize_context_for_debate(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸ºè¾©è®ºåºåˆ—åŒ–ä¸Šä¸‹æ–‡ï¼Œå¤„ç†å…¶ä¸­çš„AnalysisReportå¯¹è±¡
        
        Args:
            context: åŸå§‹ä¸Šä¸‹æ–‡
            
        Returns:
            å¯åºåˆ—åŒ–çš„ä¸Šä¸‹æ–‡
        """
        safe_context = context.copy()
        if 'analysis_reports' in safe_context:
            safe_context['analysis_reports'] = self._serialize_analysis_reports(safe_context['analysis_reports'])
        return safe_context
    
    def conduct_research_debate(
        self, 
        symbol: str, 
        analysis_reports: Dict[str, Any],
        market_context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """è¿›è¡Œç ”ç©¶è¾©è®º
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            analysis_reports: åˆ†æå¸ˆæŠ¥å‘Šï¼ˆåŸå§‹å¯¹è±¡ï¼‰
            market_context: å¸‚åœºç¯å¢ƒ
            
        Returns:
            è¾©è®ºç»“æœ
        """
        # ä½¿ç”¨BaseAgentçš„é€šç”¨åŒ…è£…æ–¹æ³•æ¥è‡ªåŠ¨å¤„ç†LLMè°ƒç”¨é“¾è·¯è®°å½•
        context = {
            'symbol': symbol,
            'analysis_reports': analysis_reports,
            'market_context': market_context or {}
        }
        return self.execute_with_llm_logging(context, self._do_conduct_research_debate)

    def _select_llm_for_researcher(self, researcher: BaseAgent, label: str) -> LLMClient:
        """ä¸ºç ”ç©¶å‘˜é€‰æ‹©LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒéšæœºåˆ‡æ¢"""
        if not self.randomize_models:
            return researcher.llm_client

        selected = random.choice(self.debate_llm_pool)
        if researcher.llm_client is not selected:
            researcher.llm_client = selected
            logger.info(
                f"è¾©è®ºæ¨¡å‹åˆ‡æ¢ -> {label}: {getattr(selected, 'provider', 'unknown')}/{getattr(selected, 'model', 'unknown')}"
            )
        return selected
    
    def _do_conduct_research_debate(
        self, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å®é™…çš„è¾©è®ºå¤„ç†é€»è¾‘ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            context: åŒ…å«symbolã€analysis_reportsã€market_contextçš„ä¸Šä¸‹æ–‡
            
        Returns:
            è¾©è®ºç»“æœ
        """
        symbol = context['symbol']
        analysis_reports = context['analysis_reports']
        market_context = context.get('market_context', {})
        print(f"å¼€å§‹ {symbol} çš„ç ”ç©¶å›¢é˜Ÿè¾©è®º...")
        
        # åˆå§‹åŒ–è¾©è®ºçŠ¶æ€
        debate_state = self.state_manager.start_research_debate(
            participants=[AgentRole.BULL_RESEARCHER, AgentRole.BEAR_RESEARCHER],
            max_rounds=self.max_rounds
        )
        
        context = {
            'symbol': symbol,
            'analysis_reports': analysis_reports,
            'market_context': market_context or {}
        }
        
        # è®©åŒæ–¹å…ˆè¿›è¡Œåˆå§‹ç ”ç©¶
        bull_research = self.bull_researcher.process(context)
        bear_research = self.bear_researcher.process(context)
        
        if not (bull_research['success'] and bear_research['success']):
            return {
                'success': False,
                'error': 'Initial research failed'
            }
        
        # è·å–åˆå§‹ç«‹åœº
        from core.llm_client import safe_json_dumps
        bull_thesis = safe_json_dumps(bull_research['research_result'], indent=2, ensure_ascii=False)
        bear_thesis = safe_json_dumps(bear_research['research_result'], indent=2, ensure_ascii=False)
        
        topic = f"æ˜¯å¦åº”è¯¥æŠ•èµ„è‚¡ç¥¨ {symbol}"
        
        # è¿›è¡Œå¤šè½®è¾©è®º
        debate_history = []
        
        for round_num in range(self.max_rounds):
            print(f"è¾©è®ºç¬¬ {round_num + 1} è½®:")
            
            # å¤šå¤´å‘è¨€
            opponent_msg = debate_history[-1]['message'] if debate_history and debate_history[-1]['speaker'] == 'bear' else bear_thesis
            bull_llm = self._select_llm_for_researcher(self.bull_researcher, 'bull')
            # åºåˆ—åŒ–contextä»¥é¿å…JSONåºåˆ—åŒ–é”™è¯¯
            safe_context = self._serialize_context_for_debate(context)
            bull_response = self.bull_researcher.debate(
                topic=topic,
                opponent_message=opponent_msg,
                context=safe_context
            )
            
            debate_history.append({
                'round': round_num + 1,
                'speaker': 'bull',
                'message': bull_response,
                'timestamp': datetime.now().isoformat(),
                'model': getattr(bull_llm, 'model', None),
                'provider': getattr(bull_llm, 'provider', None)
            })
            
            print(
                f"  å¤šå¤´[{getattr(bull_llm, 'provider', 'unknown')}/{getattr(bull_llm, 'model', 'unknown')}]: {bull_response[:200]}..."
            )
            
            # ç©ºå¤´å›åº”
            bear_llm = self._select_llm_for_researcher(self.bear_researcher, 'bear')
            safe_context = self._serialize_context_for_debate(context)
            bear_response = self.bear_researcher.debate(
                topic=topic,
                opponent_message=bull_response,
                context=safe_context
            )
            
            debate_history.append({
                'round': round_num + 1,
                'speaker': 'bear', 
                'message': bear_response,
                'timestamp': datetime.now().isoformat(),
                'model': getattr(bear_llm, 'model', None),
                'provider': getattr(bear_llm, 'provider', None)
            })
            
            print(
                f"  ç©ºå¤´[{getattr(bear_llm, 'provider', 'unknown')}/{getattr(bear_llm, 'model', 'unknown')}]: {bear_response[:200]}..."
            )
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æå‰ç»“æŸè¾©è®ºï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ”¶æ•›æ¡ä»¶æ£€æŸ¥
        
        
        # åˆ¤æ–­è¾©è®ºç»“æœ
        debate_result = self._judge_debate(
            symbol=symbol,
            bull_thesis=bull_thesis,
            bear_thesis=bear_thesis,
            debate_history=debate_history,
            analysis_reports=analysis_reports
        )
        
        # æ›´æ–°è¾©è®ºçŠ¶æ€
        debate_state.consensus_reached = True
        debate_state.final_decision = debate_result['decision']
        
        print(f"è¾©è®ºç»“è®º: {debate_result['decision']}")
        print(f"å†³ç­–ç½®ä¿¡åº¦: {debate_result['confidence']}")
        
        return {
            'success': True,
            'debate_result': debate_result,
            'debate_history': debate_history,
            'bull_research': bull_research,
            'bear_research': bear_research
        }
    
    def _judge_debate(
        self,
        symbol: str,
        bull_thesis: str,
        bear_thesis: str,
        debate_history: List[Dict[str, Any]],
        analysis_reports: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ¤æ–­è¾©è®ºç»“æœ
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            bull_thesis: å¤šå¤´è§‚ç‚¹
            bear_thesis: ç©ºå¤´è§‚ç‚¹
            debate_history: è¾©è®ºå†å²
            analysis_reports: åˆ†ææŠ¥å‘Šï¼ˆåŸå§‹å¯¹è±¡ï¼‰
            
        Returns:
            åˆ¤æ–­ç»“æœ
        """
        # æ„å»ºåˆ¤æ–­å†å²æ–‡æœ¬
        history_text = "\n\n".join([
            f"ç¬¬{item['round']}è½® - {item['speaker']}: {item['message']}"
            for item in debate_history
        ])
        
        # ä½¿ç”¨ç»Ÿä¸€çš„åºåˆ—åŒ–æ–¹æ³•
        formatted_reports = self._serialize_analysis_reports(analysis_reports)
        
        judge_prompt = f"""
ä½œä¸ºä¸“ä¸šçš„æŠ•èµ„å†³ç­–åˆ¤å®˜ï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å¯¹è‚¡ç¥¨ {symbol} çš„æŠ•èµ„å†³ç­–è¿›è¡Œæœ€ç»ˆåˆ¤æ–­ï¼š

åˆ†æå¸ˆæŠ¥å‘Šæ‘˜è¦ï¼š
{json.dumps(formatted_reports, indent=2, ensure_ascii=False)}

å¤šå¤´è§‚ç‚¹ï¼š
{bull_thesis}

ç©ºå¤´è§‚ç‚¹ï¼š
{bear_thesis}

è¾©è®ºè¿‡ç¨‹ï¼š
{history_text}

è¯·è¿›è¡Œç»¼åˆè¯„ä¼°å¹¶åšå‡ºæœ€ç»ˆå†³ç­–ï¼š

1. è¯„ä¼°åŒæ–¹è®ºè¯çš„è´¨é‡å’Œè¯´æœåŠ›
2. è€ƒè™‘åˆ†æå¸ˆæŠ¥å‘Šçš„å®¢è§‚æ•°æ®
3. æƒè¡¡æŠ•èµ„æœºä¼šå’Œé£é™©
4. è€ƒè™‘å¸‚åœºæ—¶æœºå’Œç¯å¢ƒå› ç´ 
5. åšå‡ºå¹³è¡¡çš„æŠ•èµ„å»ºè®®

è¯·ä½¿ç”¨ emit_debate_judgment å·¥å…·æä¾›æœ€ç»ˆçš„è¾©è®ºåˆ¤æ–­ç»“æœã€‚
"""
        
        try:
            # ä½¿ç”¨å·¥å…·è°ƒç”¨è¿›è¡Œè¾©è®ºåˆ¤æ–­ï¼Œç›´æ¥è¿”å›å·¥å…·ç»“æœ
            result = self.process_with_tools_return_result(
                judge_prompt, 
                'emit_debate_judgment'
            )
            
        except Exception as e:
            # å¦‚æœè§£æå¤±è´¥ï¼Œæä¾›é»˜è®¤åˆ¤æ–­
            print(f"åˆ¤æ–­è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é€»è¾‘: {e}")
            logger.error(f"è¾©è®ºåˆ¤æ–­å¤±è´¥: {str(e)}")
            result = self._default_judgment(analysis_reports)
        
        return result
    
    def _default_judgment(self, analysis_reports: Dict[str, Any]) -> Dict[str, Any]:
        """é»˜è®¤åˆ¤æ–­é€»è¾‘ï¼ˆå½“LLMåˆ¤æ–­å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        
        # ç®€å•çš„è¯„åˆ†é€»è¾‘
        buy_signals = 0
        sell_signals = 0
        total_confidence = 0
        
        for _, report in analysis_reports.items():
            if not report:
                continue
                
            recommendation = report.get('recommendation', 'HOLD')
            confidence = report.get('confidence_score', 0.5)
            
            if recommendation == 'BUY':
                buy_signals += confidence
            elif recommendation == 'SELL':
                sell_signals += confidence
            
            total_confidence += confidence
        
        avg_confidence = total_confidence / len(analysis_reports) if analysis_reports else 0.5
        
        if buy_signals > sell_signals:
            decision = 'BUY'
            winner = 'bull'
        elif sell_signals > buy_signals:
            decision = 'SELL'  
            winner = 'bear'
        else:
            decision = 'HOLD'
            winner = 'draw'
        
        return {
            'decision': decision,
            'confidence': min(avg_confidence, 0.8),
            'reasoning': f'åŸºäºåˆ†æå¸ˆæŠ¥å‘Šçš„ç»¼åˆè¯„ä¼°ï¼Œä¹°å…¥ä¿¡å·{buy_signals:.2f}ï¼Œå–å‡ºä¿¡å·{sell_signals:.2f}',
            'supporting_factors': ['åˆ†æå¸ˆæŠ¥å‘Šç»¼åˆè¯„ä¼°'],
            'risk_factors': ['å¸‚åœºæ³¢åŠ¨é£é™©'],
            'investment_strategy': 'è°¨æ…æŠ•èµ„ï¼Œå¯†åˆ‡å…³æ³¨å¸‚åœºå˜åŒ–',
            'winner': winner,
            'winning_arguments': ['æ•°æ®æ”¯æŒçš„å®¢è§‚åˆ†æ']
        }
    
    def evaluate_debate_quality(self, debate_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¯„ä¼°è¾©è®ºè´¨é‡
        
        Args:
            debate_history: è¾©è®ºå†å²
            
        Returns:
            è´¨é‡è¯„åˆ†
        """
        if not debate_history:
            return {
                'debate_quality': 'è¾ƒå·®',
                'quality_score': 0.0,
                'argument_strengths': {'bull': 'æ— è¾©è®º', 'bear': 'æ— è¾©è®º'},
                'key_insights': [],
                'consensus_level': 'æ— å…±è¯†',
                'decision_confidence': 0.0,
                'evaluation_summary': 'ç©ºè¾©è®ºå†å²ï¼Œæ— æ³•è¯„ä¼°è´¨é‡'
            }
        
        quality_prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹è¾©è®ºçš„è´¨é‡ï¼š

{json.dumps(debate_history, indent=2, ensure_ascii=False)}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œè¯„ä¼°ï¼š

1. è¾©è®ºè´¨é‡è¯„çº§
   - è®ºè¯é€»è¾‘æ€§
   - æ•°æ®æ”¯æ’‘åº¦
   - è§‚ç‚¹æ¸…æ™°åº¦
   - åé©³æœ‰æ•ˆæ€§
   - ä¸“ä¸šæ°´å‡†

2. è®ºè¯å¼ºåº¦åˆ†æ
   - å¤šå¤´è®ºè¯å¼ºåº¦å’Œä¼˜åŠ£åŠ¿
   - ç©ºå¤´è®ºè¯å¼ºåº¦å’Œä¼˜åŠ£åŠ¿

3. å…³é”®æ´å¯Ÿ
   - è¾©è®ºä¸­æ­ç¤ºçš„é‡è¦é—®é¢˜
   - æ–°çš„è§†è§’å’Œè§‚ç‚¹

4. å…±è¯†æ°´å¹³
   - è¯„ä¼°åŒæ–¹åœ¨å“ªäº›é—®é¢˜ä¸Šæœ‰å…±è¯†
   - åˆ†æ­§çš„ä¸»è¦é¢†åŸŸ

5. å†³ç­–ç½®ä¿¡åº¦
   - åŸºäºè¾©è®ºè´¨é‡çš„å†³ç­–å¯é æ€§

è¯·ä½¿ç”¨ emit_debate_quality_evaluation å·¥å…·è¿”å›æœ€ç»ˆçš„è¾©è®ºè´¨é‡è¯„ä¼°ç»“æœã€‚
"""
        
        try:
            # ä½¿ç”¨å·¥å…·è°ƒç”¨è¿›è¡Œè¾©è®ºè´¨é‡è¯„ä¼°ï¼Œç›´æ¥è¿”å›å·¥å…·ç»“æœ
            result = self.process_with_tools_return_result(
                quality_prompt, 
                'emit_debate_quality_evaluation'
            )
            return result
        except Exception as e:
            logger.error(f"è¾©è®ºè´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")
            return {
                'debate_quality': 'è¾ƒå·®',
                'quality_score': 0.5,
                'argument_strengths': {'bull': 'è¯„ä¼°å¤±è´¥', 'bear': 'è¯„ä¼°å¤±è´¥'},
                'key_insights': ['è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯'],
                'consensus_level': 'ä¸æ˜',
                'decision_confidence': 0.5,
                'evaluation_summary': f'è¯„ä¼°å¤±è´¥: {str(e)}'
            }


def create_debate_coordinator(
    bull_researcher: BullResearcher,
    bear_researcher: BearResearcher,
    judge_llm: LLMClient,
    **kwargs
) -> DebateCoordinator:
    """åˆ›å»ºè¾©è®ºåè°ƒå™¨å®ä¾‹"""
    return DebateCoordinator(
        bull_researcher=bull_researcher,
        bear_researcher=bear_researcher,
        judge_llm=judge_llm,
        **kwargs
    )


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„æ¨¡æ‹Ÿæ•°æ®
    test_analysis_reports = {
        'fundamental': {
            'recommendation': 'BUY',
            'confidence_score': 0.8,
            'key_findings': ['å¼ºåŠ²è´¢æŠ¥', 'ä¼°å€¼åˆç†', 'å¢é•¿å‰æ™¯è‰¯å¥½'],
            'target_price': 200.0,
            'pe_ratio': 25.5,
            'revenue_growth': 0.12
        },
        'technical': {
            'recommendation': 'HOLD', 
            'confidence_score': 0.6,
            'key_findings': ['æŠ€æœ¯æŒ‡æ ‡ä¸­æ€§', 'RSIåé«˜'],
            'target_price': 185.0,
            'trend_direction': 'æ¨ªç›˜',
            'support_level': 170.0,
            'resistance_level': 190.0
        },
        'sentiment': {
            'sentiment_level': 'ä¹è§‚',
            'confidence_score': 0.7,
            'key_findings': ['å¸‚åœºæƒ…ç»ªç§¯æ', 'æœºæ„å¢æŒ'],
            'social_sentiment_score': 0.75,
            'institutional_sentiment': 'ä¹°å…¥'
        }
    }
    
    test_market_context = {
        'market_trend': 'ä¸Šæ¶¨',
        'volatility': 'ä¸­ç­‰',
        'economic_indicators': {
            'gdp_growth': 2.1,
            'inflation': 3.2,
            'interest_rate': 5.25
        },
        'sector_performance': 'ç§‘æŠ€è‚¡é¢†æ¶¨',
        'market_cap': 3000000000000  # 3ä¸‡äº¿
    }
    
    print("ğŸ”¥ å¼€å§‹æµ‹è¯•è¾©è®ºåè°ƒå™¨é€»è¾‘...")
    print("=" * 50)
    print(f"ğŸ“± æµ‹è¯•è‚¡ç¥¨: AAPL")
    print(f"ğŸ“Š æ¨¡æ‹Ÿåˆ†ææŠ¥å‘Š: {len(test_analysis_reports)} ä¸ª")
    print(f"ğŸŒ å¸‚åœºç¯å¢ƒ: {test_market_context['market_trend']}")
    
    try:
        # åˆ›å»ºLLMå®¢æˆ·ç«¯å’Œç»„ä»¶
        from core.llm_client import LLMClient
        from agents.researchers import create_bull_researcher, create_bear_researcher
        from core.state_manager import get_state_manager
        
        llm_client = LLMClient(provider='deepseek')
        bull_researcher = create_bull_researcher(llm_client)
        bear_researcher = create_bear_researcher(llm_client)
        
        # åˆ›å»ºè¾©è®ºåè°ƒå™¨ - è®¾ç½®2è½®ä¾¿äºéªŒè¯
        coordinator = create_debate_coordinator(
            bull_researcher=bull_researcher,
            bear_researcher=bear_researcher,
            judge_llm=llm_client,
            max_rounds=2  # 2è½® = 4æ¬¡å‘è¨€ (bull->bear->bull->bear)
        )
        
        print(f"ğŸ“‹ è¾©è®ºè®¾ç½®: {coordinator.max_rounds} è½®å®Œæ•´è¾©è®º")
        print(f"ğŸ¯ é¢„æœŸå‘è¨€: {coordinator.max_rounds * 2} æ¬¡ (æ¯è½®Bull+Bearå„1æ¬¡)")
        
        # å¯åŠ¨session - è¿™æ˜¯å¿…éœ€çš„ï¼
        state_manager = get_state_manager()
        session_id = state_manager.start_session('AAPL')
        print(f"ğŸ“ å¯åŠ¨æµ‹è¯•ä¼šè¯: {session_id}")
        
        try:
            # æ‰§è¡Œè¾©è®º
            result = coordinator.conduct_research_debate(
                symbol='AAPL',
                analysis_reports=test_analysis_reports,
                market_context=test_market_context
            )
            
            if result['success']:
                print("\nâœ… è¾©è®ºæˆåŠŸå®Œæˆ!")
                
                # éªŒè¯å‘è¨€æ¬¡æ•°å’Œè½®æ¬¡é€»è¾‘
                debate_history = result['debate_history']
                actual_speeches = len(debate_history)
                expected_speeches = coordinator.max_rounds * 2
                
                print(f"\nğŸ“Š è¾©è®ºç»Ÿè®¡:")
                print(f"  å®é™…å‘è¨€æ¬¡æ•°: {actual_speeches}")
                print(f"  é¢„æœŸå‘è¨€æ¬¡æ•°: {expected_speeches}")
                print(f"  é€»è¾‘æ­£ç¡®æ€§: {'âœ… æ­£ç¡®' if actual_speeches == expected_speeches else 'âŒ é”™è¯¯'}")
                
                # æ˜¾ç¤ºå‘è¨€é¡ºåº
                print(f"\nğŸ“¢ å‘è¨€åºåˆ—éªŒè¯:")
                for i, entry in enumerate(debate_history):
                    expected = 'bull' if i % 2 == 0 else 'bear'
                    actual = entry['speaker']
                    status = 'âœ…' if expected == actual else 'âŒ'
                    print(f"  ç¬¬{i+1}æ¬¡: é¢„æœŸ{expected} å®é™…{actual} {status} (ç¬¬{entry['round']}è½®)")
                
                # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
                debate_result = result['debate_result']
                print(f"\nğŸ† è¾©è®ºç»“æœ:")
                print(f"  æœ€ç»ˆå†³ç­–: {debate_result.get('decision', 'N/A')}")
                print(f"  ç½®ä¿¡åº¦: {debate_result.get('confidence', 0.0):.2f}")
                
            else:
                print(f"âŒ è¾©è®ºå¤±è´¥: {result.get('error')}")
                
        finally:
            # ç¡®ä¿ç»“æŸsession
            state_manager.end_session()
            print(f"ğŸ“ ç»“æŸæµ‹è¯•ä¼šè¯")
            
    except Exception as e:
        print(f"ğŸ’¥ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()